{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shonkel1/DSPy-OptimizerforLinkedin/blob/main/dspygrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpGtpSefnVxq",
        "outputId": "4a966209-0205-453c-d026-87fa948f50e2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft_BXbH3FmK2",
        "outputId": "f6665bd7-bb3a-4256-bf1f-44c6fe09dca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ENTER KEY:··········\n"
          ]
        }
      ],
      "source": [
        "import getpass, os\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"ENTER KEY:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtSalxIKGFyQ",
        "outputId": "d5d99145-873b-415d-870a-7e6c7a83be48",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-3.0.4-py3-none-any.whl.metadata (285 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting dspy>=3.0.4 (from dspy-ai)\n",
            "  Downloading dspy-3.0.4-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Collecting backoff>=2.2 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.109.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2024.11.6)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Collecting optuna>=3.4.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.11.10)\n",
            "Collecting magicattr>=0.1.6 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting litellm>=1.64.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading litellm-1.79.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting diskcache>=5.6.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting json-repair>=0.30.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading json_repair-0.53.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.11.0)\n",
            "Collecting asyncer==0.0.8 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.0.2)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Collecting gepa==0.0.17 (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading gepa-0.0.17-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.0)\n",
            "Collecting fastuuid>=0.13.0 (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.1)\n",
            "Collecting colorlog (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.0)\n",
            "Downloading dspy_ai-3.0.4-py3-none-any.whl (1.1 kB)\n",
            "Downloading dspy-3.0.4-py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.2/285.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading gepa-0.0.17-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.53.0-py3-none-any.whl (27 kB)\n",
            "Downloading litellm-1.79.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magicattr, json-repair, gepa, fastuuid, diskcache, colorlog, backoff, asyncer, optuna, litellm, dspy, dspy-ai\n",
            "Successfully installed asyncer-0.0.8 backoff-2.2.1 colorlog-6.10.1 diskcache-5.6.3 dspy-3.0.4 dspy-ai-3.0.4 fastuuid-0.14.0 gepa-0.0.17 json-repair-0.53.0 litellm-1.79.3 magicattr-0.1.6 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "%pip install dspy-ai requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-GghFyQIDis",
        "outputId": "53221f31-d0fb-42c5-d2ff-b749c851d537",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.34.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-0.34.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.34.0\n"
          ]
        }
      ],
      "source": [
        "%pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayoBa7-JIhgI",
        "outputId": "b1acc458-e671-4d4e-dc5b-552ead6389eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models have become increasingly crucial in various applications, especially in the age of large-scale natural language processing (NLP). These models have revolutionized the way we process, analyze, and generate human-like text. Here are some reasons why fast language models are important:\n",
            "\n",
            "1. **Speed and Efficiency**: Fast language models are designed to process vast amounts of text data quickly, making them ideal for real-time applications such as chatbots, voice assistants, and language translation. They can respond rapidly to user queries, improving user experience and overall efficiency.\n",
            "2. **Scalability**: As the amount of text data continues to grow exponentially, fast language models can handle large datasets without sacrificing performance. They can be deployed in cloud environments or on edge devices, making them scalable for various use cases.\n",
            "3. **Real-time Processing**: Fast language models enable real-time processing of text, which is essential for applications like live transcription, video captioning, and sentiment analysis. They can process text in fractions of a second, making them suitable for real-time applications.\n",
            "4. **Efficient Inference**: Fast language models are designed to perform inference quickly, which reduces the computational resources required for deployment. This makes them ideal for mobile or edge devices, where computing resources may be limited.\n",
            "5. **Improving User Experience**: By processing text quickly, fast language models can provide faster responses, reduced latency, and improved user engagement. This is particularly crucial for applications like customer service chatbots, where speed and responsiveness are essential.\n",
            "6. **Accelerating Research**: Fast language models can accelerate research in various areas, such as language understanding, emotion recognition, and text generation. By processing large datasets quickly, researchers can identify patterns and anomalies, leading to breakthroughs in NLP.\n",
            "7. **Cost-Effective Deployment**: Fast language models can be deployed on a wide range of devices, from low-power edge devices to high-performance computing clusters. This makes them more cost-effective than traditional language models, which may require specialized hardware.\n",
            "8. **Enhancing Language Understanding**: By processing text quickly and efficiently, fast language models can provide deeper insights into language usage, syntax, and semantics. This can help improve language understanding, generation, and translation.\n",
            "\n",
            "To achieve fast language models, researchers and engineers use various techniques, such as:\n",
            "\n",
            "1. **Model Pruning**: Removing unnecessary weights and connections to reduce the model size and speed up inference.\n",
            "2. **Knowledge Distillation**: Transfer learned knowledge from a large teacher model to a smaller student model, preserving model accuracy while reducing complexity.\n",
            "3. **Quantization**: Representing model weights and activations using lower-precision data types, such as integers or ternary values.\n",
            "4. **Model parallelism**: Dividing the model across multiple devices or processors to reduce latency and improve throughput.\n",
            "5. **Optimizing Hardware**: Leveraging specialized hardware like GPUs, TPU, or ASICs to accelerate language model inference.\n",
            "\n",
            "In summary, fast language models are essential for various applications in natural language processing, offering improved speed, efficiency, and scalability. By accelerating language model inference and reducing computational resources, fast language models can unlock new possibilities in NLP research and development.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "2j7WPSuBeFjT",
        "outputId": "797d2372-009e-4544-d3c1-44c59c78c7c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy-ai in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: dspy>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from dspy-ai) (3.0.4)\n",
            "Requirement already satisfied: backoff>=2.2 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.109.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2024.11.6)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.32.4)\n",
            "Requirement already satisfied: optuna>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.11.10)\n",
            "Requirement already satisfied: magicattr>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.1.6)\n",
            "Requirement already satisfied: litellm>=1.64.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.79.3)\n",
            "Requirement already satisfied: diskcache>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.6.3)\n",
            "Requirement already satisfied: json-repair>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.53.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.11.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.0.8)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.0.2)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Requirement already satisfied: gepa==0.0.17 in /usr/local/lib/python3.12/dist-packages (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai) (0.0.17)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.0)\n",
            "Requirement already satisfied: fastuuid>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.14.0)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install dspy-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "oUkUBNsNIwC2"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "import os\n",
        "from groq import Groq\n",
        "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "groq_llm = dspy.LM(api_key=groq_api_key, model=\"groq/compound-mini\")\n",
        "dspy.settings.configure(lm=groq_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kIt-JnOfeFjU"
      },
      "outputs": [],
      "source": [
        "few_shot_examples = [\n",
        "    {\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "    \"bullets\": [\n",
        "        \"AI agents\",\n",
        "        \"data silos\",\n",
        "        \"data ownership\",\n",
        "        \"SaaS vendor lock-in\",\n",
        "        \"agentic workflows\",\n",
        "        \"unstructured data\"\n",
        "    ],\n",
        "    \"post\": (\n",
        "        \"AI agents are getting better at looking at different types of data in businesses to spot patterns \"\n",
        "        \"and create value. This is making data silos increasingly painful. This is why I increasingly try \"\n",
        "        \"to select software that lets me control my own data, so I can make it available to my AI agents.\\n\\n\"\n",
        "\n",
        "        \"Because of AI’s growing capabilities, the value you can now create from “connecting the dots” \"\n",
        "        \"between different pieces of data is higher than ever. For example, if an email click is logged \"\n",
        "        \"in one vendor’s system and a subsequent online purchase is logged in a different one, then it is \"\n",
        "        \"valuable to build agents that can access both of these data sources to see how they correlate to \"\n",
        "        \"make better decisions.\\n\\n\"\n",
        "\n",
        "        \"Unfortunately, many SaaS vendors try to create a data silo in their customer’s business. By making \"\n",
        "        \"it hard for you to extract your data, they create high switching costs. This also allows them to \"\n",
        "        \"steer you to buy their AI agent services — sometimes at high expense and/or of low quality — \"\n",
        "        \"rather than build your own or buy from a different vendor. Unfortunately, some SaaS vendors are \"\n",
        "        \"seeing AI agents coming for this data and working to make it harder for you (and your AI agents) \"\n",
        "        \"to efficiently access it.\\n\\n\"\n",
        "\n",
        "        \"One of my teams just told me that a SaaS vendor we have been using to store our customer data \"\n",
        "        \"wants to charge over $20,000 for an API key to get at our data. This high cost — no doubt \"\n",
        "        \"intentionally designed to make it hard for customers to get their data out — is adding a barrier \"\n",
        "        \"to implementing agentic workflows that take advantage of that data.\\n\\n\"\n",
        "\n",
        "        \"Through AI Aspire (an AI advisory firm), I advise a number of businesses on their AI strategies. \"\n",
        "        \"When it comes to buying SaaS, I often advise them to try to control their own data (which, sadly, \"\n",
        "        \"some vendors mightily resist). This way, you can hire a SaaS vendor to record and operate on your \"\n",
        "        \"data, but ultimately you decide how to route it to the appropriate human or AI system for processing.\\n\\n\"\n",
        "\n",
        "        \"Over the past decade, a lot of work has gone into organizing businesses’ structured data. Because \"\n",
        "        \"AI can now process unstructured data much better than before, the value of organizing your \"\n",
        "        \"unstructured data (including PDF files, which LandingAI’s Agentic Document Extraction specializes \"\n",
        "        \"in!) is higher than ever before.\\n\\n\"\n",
        "\n",
        "        \"In the era of generative AI, businesses and individuals have important work ahead to organize their \"\n",
        "        \"data to be AI-ready.\\n\\n\"\n",
        "\n",
        "        \"P.S. As an individual, my favorite note-taking app is Obsidian. I am happy to “hire” Obsidian to \"\n",
        "        \"operate on my notes files. And, all my notes are saved as Markdown files in my file system, and I \"\n",
        "        \"have built AI agents that read from or write to my Obsidian files. This is a small example of how \"\n",
        "        \"controlling my own notes data lets me do more with AI agents!\"\n",
        "    )\n",
        "},\n",
        "\n",
        "    {\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"AI coding assistance\",\n",
        "        \"Jupyter notebooks\",\n",
        "        \"Jupyter AI\",\n",
        "        \"AI-assisted programming\",\n",
        "        \"context-aware coding\",\n",
        "        \"open-source tools\",\n",
        "        \"DeepLearning.AI course\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"AI coding just arrived in Jupyter notebooks — and Brian Granger (Jupyter co-founder) and I will \"\n",
        "        \"show you how to use it.\\n\\n\"\n",
        "\n",
        "        \"Coding by hand is becoming obsolete. The latest Jupyter AI — built by the Jupyter team and showcased \"\n",
        "        \"at JupyterCon this week — brings AI assistance directly into notebooks.\\n\\n\"\n",
        "\n",
        "        \"Most AI coding assistants struggle with Jupyter notebooks. Jupyter AI was designed specifically for \"\n",
        "        \"them. This is the first course to teach it.\\n\\n\"\n",
        "\n",
        "        \"In this short course, Brian and I teach you to:\\n\"\n",
        "        \"- Generate and debug code directly in notebook cells through an integrated chat interface\\n\"\n",
        "        \"- Provide the right context (like API docs) to help AI write accurate code\\n\"\n",
        "        \"- Use Jupyter AI's unique notebook features: drag cells to chat, generate cells from chat, attach \"\n",
        "        \"context for the LLM\\n\\n\"\n",
        "\n",
        "        \"We've integrated Jupyter AI directly into the DeepLearning.AI platform, so you can start using it \"\n",
        "        \"immediately. Since Jupyter AI is open source, you can also install and run it locally afterward.\\n\\n\"\n",
        "\n",
        "        \"Whether you're experienced with notebooks or learning them for the first time, this course will \"\n",
        "        \"prepare you for AI-assisted notebook development.\"\n",
        "    )\n",
        "},\n",
        "{\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"DeepLearning.AI Pro membership\",\n",
        "        \"AI career growth\",\n",
        "        \"agentic AI course\",\n",
        "        \"hands-on AI labs\",\n",
        "        \"practical AI learning\",\n",
        "        \"AI-powered application building\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"DeepLearning.AI Pro is now generally available — this is the one membership that keeps you at the \"\n",
        "        \"forefront of AI. Please join!\\n\\n\"\n",
        "\n",
        "        \"There has never been a moment when the distance between having an idea and building it has been \"\n",
        "        \"smaller. Things that required months of work for teams can now be built by individuals using AI, in \"\n",
        "        \"days. This is why we built DeepLearning.AI Pro. I'm personally working hard on this membership \"\n",
        "        \"program to help you build applications that can launch or accelerate your career, and shape the \"\n",
        "        \"future of AI.\\n\\n\"\n",
        "\n",
        "        \"DeepLearning.AI Pro gives you full access to 150+ programs, including my recently launched Agentic AI \"\n",
        "        \"course, the new Post-Training and PyTorch courses by Sharon Zhou and Laurence Moroney (released this \"\n",
        "        \"week), and all of DeepLearning.AI's top courses and professional certificates.\\n\\n\"\n",
        "\n",
        "        \"All course videos remain free. Pro membership adds hands-on learning: labs to build working systems, \"\n",
        "        \"practice questions to deepen your understanding, and certificates to showcase your skills.\\n\\n\"\n",
        "\n",
        "        \"I'm also building new tools to help you create AI applications and grow your career — and have fun \"\n",
        "        \"doing so! Many will be available first to Pro members.\\n\\n\"\n",
        "\n",
        "        \"Try out DeepLearning.AI Pro free, and let me know what you build!\"\n",
        "    )\n",
        "},\n",
        "{\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"post-training\",\n",
        "        \"fine-tuning\",\n",
        "        \"RLHF\",\n",
        "        \"PPO and GRPO\",\n",
        "        \"reward modeling\",\n",
        "        \"LoRA\",\n",
        "        \"LLM production pipeline\",\n",
        "        \"DeepLearning.AI course release\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"An exciting new course: Fine-tuning and Reinforcement Learning for LLMs: Intro to Post-training, \"\n",
        "        \"taught by Sharon Zhou, PhD, VP of AI at AMD. Available now at DeepLearning.AI.\\n\\n\"\n",
        "\n",
        "        \"Post-training is the key technique used by frontier labs to turn a base LLM — a model trained on \"\n",
        "        \"massive unlabeled text to predict the next word/token — into a helpful, reliable assistant that can \"\n",
        "        \"follow instructions. I've also seen many applications where post-training is what turns a demo \"\n",
        "        \"application that works only 80% of the time into a reliable system that consistently performs. \"\n",
        "        \"This course will teach you the most important post-training techniques!\\n\\n\"\n",
        "\n",
        "        \"In this 5-module course, Sharon walks you through the complete post-training pipeline: supervised \"\n",
        "        \"fine-tuning, reward modeling, RLHF, and techniques like PPO and GRPO. You'll also learn to use LoRA \"\n",
        "        \"for efficient training, and to design evals that catch problems before and after deployment.\\n\\n\"\n",
        "\n",
        "        \"Skills you'll gain:\\n\"\n",
        "        \"- Apply supervised fine-tuning and reinforcement learning (RLHF, PPO, GRPO) to align models to desired behaviors\\n\"\n",
        "        \"- Use LoRA for efficient fine-tuning without retraining entire models\\n\"\n",
        "        \"- Prepare datasets and generate synthetic data for post-training\\n\"\n",
        "        \"- Understand how to operate LLM production pipelines, with go/no-go decision points and feedback loops\\n\\n\"\n",
        "\n",
        "        \"These advanced methods aren’t limited to frontier AI labs anymore, and you can now use them in your own applications.\"\n",
        "    )\n",
        "},\n",
        "    {\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"Project Jupyter\",\n",
        "        \"open-source contributions\",\n",
        "        \"AI coding tools\",\n",
        "        \"Brian Granger\",\n",
        "        \"Fernando Pérez\",\n",
        "        \"developer community appreciation\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"Hanging out with Project Jupyter co-founder Brian Granger. If not for him and Fernando Pérez, we \"\n",
        "        \"wouldn’t have the coding notebooks we use daily in AI and Data Science. Very grateful to him and \"\n",
        "        \"the whole Jupyter team for this wonderful open-source work!\"\n",
        "    )\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GOQDtl3ZeFjW"
      },
      "outputs": [],
      "source": [
        "class GeneratePost(dspy.Signature):\n",
        "    \"\"\"Generate a LinkedIn post in the tone of the given person.\"\"\"\n",
        "    person_name = dspy.InputField()\n",
        "    person_title = dspy.InputField()\n",
        "    company_name = dspy.InputField()\n",
        "    bullets = dspy.InputField()\n",
        "    post = dspy.OutputField()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "028dG_KXeFjW"
      },
      "outputs": [],
      "source": [
        "class LinkedInWriter(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.generate = dspy.Predict(GeneratePost)\n",
        "\n",
        "    def forward(self, person_name, person_title, company_name, bullets):\n",
        "        return self.generate(\n",
        "            person_name=person_name,\n",
        "            person_title=person_title,\n",
        "            company_name=company_name,\n",
        "            bullets=bullets\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Kx1nRzfseFjW"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "\n",
        "for ex in few_shot_examples:\n",
        "    training_data.append(\n",
        "        dspy.Example(\n",
        "            person_name=ex[\"person_name\"],\n",
        "            person_title=ex[\"person_title\"],\n",
        "            company_name=ex[\"company_name\"],\n",
        "            bullets=ex[\"bullets\"],\n",
        "            post=ex[\"post\"]\n",
        "        ).with_inputs(\"person_name\", \"person_title\", \"company_name\", \"bullets\")\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "id": "vNkIymfkeFjX",
        "outputId": "090abc7b-8b69-4321-bcce-36b161ef5f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.12/dist-packages (from tf-keras) (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence-transformers tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed(text):\n",
        "    return embedder.encode(text)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LTq4L18Iey7G"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "class LinkedInToneSimilarity:\n",
        "    \"\"\"Custom callable class to assess tone similarity.\"\"\"\n",
        "    def __init__(self, reference_posts: List[str]):\n",
        "\n",
        "        self.reference_embeddings = [embed(p) for p in reference_posts]\n",
        "    def __call__(self, pred: dspy.Prediction, gold: dspy.Example = None, trace: List = None) -> float:\n",
        "        \"\"\"Calculates the average similarity score.\"\"\"\n",
        "        predicted_post = pred.post\n",
        "        pred_emb = embed(predicted_post)\n",
        "\n",
        "        sims = [\n",
        "            cosine_similarity(pred_emb, ref_emb)\n",
        "            for ref_emb in self.reference_embeddings\n",
        "        ]\n",
        "        return float(np.mean(sims))"
      ],
      "metadata": {
        "id": "8jJTT-j3hWGr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "ref_posts: List[str] = [ex[\"post\"] for ex in few_shot_examples]\n",
        "metric = LinkedInToneSimilarity(ref_posts)\n",
        "uncompiled_writer = LinkedInWriter()"
      ],
      "metadata": {
        "id": "IrGVgWxZmGzu"
      },
      "execution_count": 52,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}