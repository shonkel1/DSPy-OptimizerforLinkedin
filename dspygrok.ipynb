{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shonkel1/DSPy-OptimizerforLinkedin/blob/main/dspygrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpGtpSefnVxq",
        "outputId": "e9ce440d-8f56-4675-a872-f15a4576ab29",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft_BXbH3FmK2",
        "outputId": "8a326c78-c2fc-49a6-b9dc-506f60dc47bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ENTER KEY:··········\n"
          ]
        }
      ],
      "source": [
        "import getpass, os\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"ENTER KEY:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtSalxIKGFyQ",
        "outputId": "eb1795b8-ecd3-40d7-b6d2-48a0127ab7c2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy-ai in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: dspy>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from dspy-ai) (3.0.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: backoff>=2.2 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.109.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2024.11.6)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: optuna>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.11.10)\n",
            "Requirement already satisfied: magicattr>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.1.6)\n",
            "Requirement already satisfied: litellm>=1.64.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.79.3)\n",
            "Requirement already satisfied: diskcache>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.6.3)\n",
            "Requirement already satisfied: json-repair>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.53.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.11.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.0.8)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.0.2)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Requirement already satisfied: gepa==0.0.17 in /usr/local/lib/python3.12/dist-packages (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai) (0.0.17)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.0)\n",
            "Requirement already satisfied: fastuuid>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.14.0)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install dspy-ai requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-GghFyQIDis",
        "outputId": "39ecb4bb-6ce3-47a1-f2ed-32b020ffb039",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.34.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j7WPSuBeFjT",
        "outputId": "65574613-f206-43c5-c892-a5c62961ca27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy-ai in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: dspy>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from dspy-ai) (3.0.4)\n",
            "Requirement already satisfied: backoff>=2.2 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.109.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2024.11.6)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.32.4)\n",
            "Requirement already satisfied: optuna>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.11.10)\n",
            "Requirement already satisfied: magicattr>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.1.6)\n",
            "Requirement already satisfied: litellm>=1.64.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.79.3)\n",
            "Requirement already satisfied: diskcache>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.6.3)\n",
            "Requirement already satisfied: json-repair>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.53.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.11.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.0.8)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.0.2)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Requirement already satisfied: gepa==0.0.17 in /usr/local/lib/python3.12/dist-packages (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai) (0.0.17)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.0)\n",
            "Requirement already satisfied: fastuuid>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.14.0)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install dspy-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "oUkUBNsNIwC2"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "import os\n",
        "from groq import Groq\n",
        "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "groq_llm = dspy.LM(api_key=groq_api_key, model=\"groq/llama-3.1-8b-instant\")\n",
        "dspy.settings.configure(lm=groq_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "kIt-JnOfeFjU"
      },
      "outputs": [],
      "source": [
        "few_shot_examples = [\n",
        "    {\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "    \"bullets\": [\n",
        "        \"AI agents\",\n",
        "        \"data silos\",\n",
        "        \"data ownership\",\n",
        "        \"SaaS vendor lock-in\",\n",
        "        \"agentic workflows\",\n",
        "        \"unstructured data\"\n",
        "    ],\n",
        "    \"post\": (\n",
        "        \"AI agents are getting better at looking at different types of data in businesses to spot patterns \"\n",
        "        \"and create value. This is making data silos increasingly painful. This is why I increasingly try \"\n",
        "        \"to select software that lets me control my own data, so I can make it available to my AI agents.\\n\\n\"\n",
        "\n",
        "        \"Because of AI’s growing capabilities, the value you can now create from “connecting the dots” \"\n",
        "        \"between different pieces of data is higher than ever. For example, if an email click is logged \"\n",
        "        \"in one vendor’s system and a subsequent online purchase is logged in a different one, then it is \"\n",
        "        \"valuable to build agents that can access both of these data sources to see how they correlate to \"\n",
        "        \"make better decisions.\\n\\n\"\n",
        "\n",
        "        \"Unfortunately, many SaaS vendors try to create a data silo in their customer’s business. By making \"\n",
        "        \"it hard for you to extract your data, they create high switching costs. This also allows them to \"\n",
        "        \"steer you to buy their AI agent services — sometimes at high expense and/or of low quality — \"\n",
        "        \"rather than build your own or buy from a different vendor. Unfortunately, some SaaS vendors are \"\n",
        "        \"seeing AI agents coming for this data and working to make it harder for you (and your AI agents) \"\n",
        "        \"to efficiently access it.\\n\\n\"\n",
        "\n",
        "        \"One of my teams just told me that a SaaS vendor we have been using to store our customer data \"\n",
        "        \"wants to charge over $20,000 for an API key to get at our data. This high cost — no doubt \"\n",
        "        \"intentionally designed to make it hard for customers to get their data out — is adding a barrier \"\n",
        "        \"to implementing agentic workflows that take advantage of that data.\\n\\n\"\n",
        "\n",
        "        \"Through AI Aspire (an AI advisory firm), I advise a number of businesses on their AI strategies. \"\n",
        "        \"When it comes to buying SaaS, I often advise them to try to control their own data (which, sadly, \"\n",
        "        \"some vendors mightily resist). This way, you can hire a SaaS vendor to record and operate on your \"\n",
        "        \"data, but ultimately you decide how to route it to the appropriate human or AI system for processing.\\n\\n\"\n",
        "\n",
        "        \"Over the past decade, a lot of work has gone into organizing businesses’ structured data. Because \"\n",
        "        \"AI can now process unstructured data much better than before, the value of organizing your \"\n",
        "        \"unstructured data (including PDF files, which LandingAI’s Agentic Document Extraction specializes \"\n",
        "        \"in!) is higher than ever before.\\n\\n\"\n",
        "\n",
        "        \"In the era of generative AI, businesses and individuals have important work ahead to organize their \"\n",
        "        \"data to be AI-ready.\\n\\n\"\n",
        "\n",
        "        \"P.S. As an individual, my favorite note-taking app is Obsidian. I am happy to “hire” Obsidian to \"\n",
        "        \"operate on my notes files. And, all my notes are saved as Markdown files in my file system, and I \"\n",
        "        \"have built AI agents that read from or write to my Obsidian files. This is a small example of how \"\n",
        "        \"controlling my own notes data lets me do more with AI agents!\"\n",
        "    )\n",
        "},\n",
        "\n",
        "    {\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"AI coding assistance\",\n",
        "        \"Jupyter notebooks\",\n",
        "        \"Jupyter AI\",\n",
        "        \"AI-assisted programming\",\n",
        "        \"context-aware coding\",\n",
        "        \"open-source tools\",\n",
        "        \"DeepLearning.AI course\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"AI coding just arrived in Jupyter notebooks — and Brian Granger (Jupyter co-founder) and I will \"\n",
        "        \"show you how to use it.\\n\\n\"\n",
        "\n",
        "        \"Coding by hand is becoming obsolete. The latest Jupyter AI — built by the Jupyter team and showcased \"\n",
        "        \"at JupyterCon this week — brings AI assistance directly into notebooks.\\n\\n\"\n",
        "\n",
        "        \"Most AI coding assistants struggle with Jupyter notebooks. Jupyter AI was designed specifically for \"\n",
        "        \"them. This is the first course to teach it.\\n\\n\"\n",
        "\n",
        "        \"In this short course, Brian and I teach you to:\\n\"\n",
        "        \"- Generate and debug code directly in notebook cells through an integrated chat interface\\n\"\n",
        "        \"- Provide the right context (like API docs) to help AI write accurate code\\n\"\n",
        "        \"- Use Jupyter AI's unique notebook features: drag cells to chat, generate cells from chat, attach \"\n",
        "        \"context for the LLM\\n\\n\"\n",
        "\n",
        "        \"We've integrated Jupyter AI directly into the DeepLearning.AI platform, so you can start using it \"\n",
        "        \"immediately. Since Jupyter AI is open source, you can also install and run it locally afterward.\\n\\n\"\n",
        "\n",
        "        \"Whether you're experienced with notebooks or learning them for the first time, this course will \"\n",
        "        \"prepare you for AI-assisted notebook development.\"\n",
        "    )\n",
        "},\n",
        "{\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"DeepLearning.AI Pro membership\",\n",
        "        \"AI career growth\",\n",
        "        \"agentic AI course\",\n",
        "        \"hands-on AI labs\",\n",
        "        \"practical AI learning\",\n",
        "        \"AI-powered application building\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"DeepLearning.AI Pro is now generally available — this is the one membership that keeps you at the \"\n",
        "        \"forefront of AI. Please join!\\n\\n\"\n",
        "\n",
        "        \"There has never been a moment when the distance between having an idea and building it has been \"\n",
        "        \"smaller. Things that required months of work for teams can now be built by individuals using AI, in \"\n",
        "        \"days. This is why we built DeepLearning.AI Pro. I'm personally working hard on this membership \"\n",
        "        \"program to help you build applications that can launch or accelerate your career, and shape the \"\n",
        "        \"future of AI.\\n\\n\"\n",
        "\n",
        "        \"DeepLearning.AI Pro gives you full access to 150+ programs, including my recently launched Agentic AI \"\n",
        "        \"course, the new Post-Training and PyTorch courses by Sharon Zhou and Laurence Moroney (released this \"\n",
        "        \"week), and all of DeepLearning.AI's top courses and professional certificates.\\n\\n\"\n",
        "\n",
        "        \"All course videos remain free. Pro membership adds hands-on learning: labs to build working systems, \"\n",
        "        \"practice questions to deepen your understanding, and certificates to showcase your skills.\\n\\n\"\n",
        "\n",
        "        \"I'm also building new tools to help you create AI applications and grow your career — and have fun \"\n",
        "        \"doing so! Many will be available first to Pro members.\\n\\n\"\n",
        "\n",
        "        \"Try out DeepLearning.AI Pro free, and let me know what you build!\"\n",
        "    )\n",
        "},\n",
        "{\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"post-training\",\n",
        "        \"fine-tuning\",\n",
        "        \"RLHF\",\n",
        "        \"PPO and GRPO\",\n",
        "        \"reward modeling\",\n",
        "        \"LoRA\",\n",
        "        \"LLM production pipeline\",\n",
        "        \"DeepLearning.AI course release\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"An exciting new course: Fine-tuning and Reinforcement Learning for LLMs: Intro to Post-training, \"\n",
        "        \"taught by Sharon Zhou, PhD, VP of AI at AMD. Available now at DeepLearning.AI.\\n\\n\"\n",
        "\n",
        "        \"Post-training is the key technique used by frontier labs to turn a base LLM — a model trained on \"\n",
        "        \"massive unlabeled text to predict the next word/token — into a helpful, reliable assistant that can \"\n",
        "        \"follow instructions. I've also seen many applications where post-training is what turns a demo \"\n",
        "        \"application that works only 80% of the time into a reliable system that consistently performs. \"\n",
        "        \"This course will teach you the most important post-training techniques!\\n\\n\"\n",
        "\n",
        "        \"In this 5-module course, Sharon walks you through the complete post-training pipeline: supervised \"\n",
        "        \"fine-tuning, reward modeling, RLHF, and techniques like PPO and GRPO. You'll also learn to use LoRA \"\n",
        "        \"for efficient training, and to design evals that catch problems before and after deployment.\\n\\n\"\n",
        "\n",
        "        \"Skills you'll gain:\\n\"\n",
        "        \"- Apply supervised fine-tuning and reinforcement learning (RLHF, PPO, GRPO) to align models to desired behaviors\\n\"\n",
        "        \"- Use LoRA for efficient fine-tuning without retraining entire models\\n\"\n",
        "        \"- Prepare datasets and generate synthetic data for post-training\\n\"\n",
        "        \"- Understand how to operate LLM production pipelines, with go/no-go decision points and feedback loops\\n\\n\"\n",
        "\n",
        "        \"These advanced methods aren’t limited to frontier AI labs anymore, and you can now use them in your own applications.\"\n",
        "    )\n",
        "},\n",
        "    {\n",
        "    \"person_name\": \"Andrew Ng\",\n",
        "    \"person_title\": \"Founder, DeepLearning.AI | Co-founder, Coursera\",\n",
        "    \"company_name\": \"DeepLearning.AI\",\n",
        "    \"company_industry\": \"Artificial Intelligence Education\",\n",
        "    \"company_size\": \"200–500 employees\",\n",
        "\n",
        "    \"bullets\": [\n",
        "        \"Project Jupyter\",\n",
        "        \"open-source contributions\",\n",
        "        \"AI coding tools\",\n",
        "        \"Brian Granger\",\n",
        "        \"Fernando Pérez\",\n",
        "        \"developer community appreciation\"\n",
        "    ],\n",
        "\n",
        "    \"post\": (\n",
        "        \"Hanging out with Project Jupyter co-founder Brian Granger. If not for him and Fernando Pérez, we \"\n",
        "        \"wouldn’t have the coding notebooks we use daily in AI and Data Science. Very grateful to him and \"\n",
        "        \"the whole Jupyter team for this wonderful open-source work!\"\n",
        "    )\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "GOQDtl3ZeFjW"
      },
      "outputs": [],
      "source": [
        "class GeneratePost(dspy.Signature):\n",
        "    \"\"\"Generate a LinkedIn post in the tone of the given person.\"\"\"\n",
        "    person_name = dspy.InputField()\n",
        "    person_title = dspy.InputField()\n",
        "    company_name = dspy.InputField()\n",
        "    bullets = dspy.InputField()\n",
        "    post = dspy.OutputField()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "028dG_KXeFjW"
      },
      "outputs": [],
      "source": [
        "class LinkedInWriter(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.generate = dspy.Predict(GeneratePost)\n",
        "\n",
        "    def forward(self, person_name, person_title, company_name, bullets):\n",
        "        return self.generate(\n",
        "            person_name=person_name,\n",
        "            person_title=person_title,\n",
        "            company_name=company_name,\n",
        "            bullets=bullets\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Kx1nRzfseFjW"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "\n",
        "for ex in few_shot_examples:\n",
        "    training_data.append(\n",
        "        dspy.Example(\n",
        "            person_name=ex[\"person_name\"],\n",
        "            person_title=ex[\"person_title\"],\n",
        "            company_name=ex[\"company_name\"],\n",
        "            bullets=ex[\"bullets\"],\n",
        "            post=ex[\"post\"]\n",
        "        ).with_inputs(\"person_name\", \"person_title\", \"company_name\", \"bullets\")\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNkIymfkeFjX",
        "outputId": "79f59fc5-cbbf-45e5-d5b3-96959356de80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.12/dist-packages (from tf-keras) (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence-transformers tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed(text):\n",
        "    return embedder.encode(text)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LTq4L18Iey7G"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "class LinkedInToneSimilarity:\n",
        "    \"\"\"Custom callable class to assess tone similarity.\"\"\"\n",
        "    def __init__(self, reference_posts: List[str]):\n",
        "\n",
        "        self.reference_embeddings = [embed(p) for p in reference_posts]\n",
        "    def __call__(self, pred: dspy.Prediction, gold: dspy.Example = None, trace: List = None):\n",
        "        \"\"\"Calculates the average similarity score.\"\"\"\n",
        "        predicted_post = pred.post\n",
        "        pred_emb = embed(predicted_post)\n",
        "\n",
        "        sims = [\n",
        "            cosine_similarity(pred_emb, ref_emb)\n",
        "            for ref_emb in self.reference_embeddings\n",
        "        ]\n",
        "        return float(np.mean(sims))"
      ],
      "metadata": {
        "id": "8jJTT-j3hWGr"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "ref_posts: List[str] = [ex[\"post\"] for ex in few_shot_examples]\n",
        "metric = LinkedInToneSimilarity(ref_posts)\n",
        "uncompiled_writer = LinkedInWriter()"
      ],
      "metadata": {
        "id": "IrGVgWxZmGzu"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "optimizer = dspy.BootstrapFewShot(metric=metric)\n",
        "\n",
        "optimized_writer = optimizer.compile(student=uncompiled_writer, trainset=training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFcnVv9mwR7Q",
        "outputId": "8dab6943-7a82-4540-d56f-d652acbd5532"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4/5 [00:01<00:00,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "mfile = 'memory.json'\n",
        "initial_data = []\n",
        "\n",
        "# Write the data to the file\n",
        "with open(mfile, 'w') as f:\n",
        "    json.dump(initial_data, f, indent=2)\n",
        "print(\"--- Current Files ---\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHUFGwPF6hGy",
        "outputId": "613913d3-748f-4d45-b660-a945f437ec64"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Current Files ---\n",
            "memory.json  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def load_memory():\n",
        "    \"\"\"Loads previous post content from the JSON memory file.\"\"\"\n",
        "    if os.path.exists(mfile):\n",
        "        with open(mfile, 'r') as f:\n",
        "          data = json.load(f)\n",
        "          return [item['post'] for item in data if 'post' in item]\n",
        ""
      ],
      "metadata": {
        "id": "MqUhMQoA6k0U"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_memory(data: Dict):\n",
        "    \"\"\"Saves a new post's data to the memory file.\"\"\"\n",
        "    existing_data = []\n",
        "    if os.path.exists(mfile):\n",
        "        with open(mfile, 'r') as f:\n",
        "          existing_data = json.load(f)\n",
        "    existing_data.insert(0, data)\n",
        "    existing_data = existing_data[:10]\n",
        "\n",
        "    with open(mfile, 'w') as f:\n",
        "        json.dump(existing_data, f, indent=2)\n",
        ""
      ],
      "metadata": {
        "id": "hY0gn6Sr7IWS"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Runs the CLI interface for generating LinkedIn posts.\"\"\"\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(\"🚀 DSPy-Powered LinkedIn Post Generator (CLI) 🚀\")\n",
        "    print(\"-----------------------------------------------------\")\n",
        "\n",
        "    # 1. Load Tone Cues from Memory\n",
        "    previous_posts = load_memory()\n",
        "    num_cues = len(previous_posts)\n",
        "\n",
        "    print(f\"[MEMORY] Loaded {num_cues} previous posts for tone guidance.\")\n",
        "\n",
        "    # 2. Get User Inputs\n",
        "    print(\"\\n--- Inputs ---\")\n",
        "    person_name = input(\"Enter Person's Name: \")\n",
        "    person_title = input(\"Enter Person's Title: \")\n",
        "    company_name = input(\"Enter Company Name: \")\n",
        "\n",
        "    bullets = []\n",
        "    print(\"\\nEnter 2-3 Bullet Points (Type 'done' or hit Enter on an empty line to finish):\")\n",
        "\n",
        "    while len(bullets) < 5:\n",
        "        bullet_input = input(f\"Bullet {len(bullets) + 1}: \").strip()\n",
        "        if not bullet_input or bullet_input.lower() == 'done':\n",
        "            if len(bullets) < 2:\n",
        "                print(\"Please provide at least 2 bullet points.\")\n",
        "                continue\n",
        "            break\n",
        "        bullets.append(bullet_input)\n",
        "\n",
        "    if len(bullets) < 2:\n",
        "        print(\"Generation aborted: Insufficient bullet points provided.\")\n",
        "        return\n",
        "\n",
        "    # 3. Prepare Inputs for DSPy\n",
        "    # DSPy signature expects a string of bullets\n",
        "    bullets_str = \"\\n\".join([f\"- {b}\" for b in bullets])\n",
        "\n",
        "    print(\"\\n--- Generating Post... ---\")\n",
        "\n",
        "    # Call the optimized DSPy module\n",
        "    pred = optimized_writer(\n",
        "        person_name=person_name,\n",
        "        person_title=person_title,\n",
        "        company_name=company_name,\n",
        "        bullets=bullets_str\n",
        "    )\n",
        "\n",
        "    generated_post = pred.post\n",
        "    print(generated_post)\n",
        "    print(\"\\n-----------------------------------------------------\")\n",
        "\n",
        "    # 4. Save to Memory\n",
        "    save_to_memory({\n",
        "        \"person_name\": person_name,\n",
        "        \"person_title\": person_title,\n",
        "        \"company_name\": company_name,\n",
        "        \"bullets\": bullets,\n",
        "        \"post\": generated_post\n",
        "    })\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qxij4lm8CXC",
        "outputId": "f6b6d0f9-483f-4dd2-fdac-f5e4fb2a67ba"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------\n",
            "🚀 DSPy-Powered LinkedIn Post Generator (CLI) 🚀\n",
            "-----------------------------------------------------\n",
            "[MEMORY] Loaded 5 previous posts for tone guidance.\n",
            "\n",
            "--- Inputs ---\n",
            "Enter Person's Name: shounak\n",
            "Enter Person's Title: mr\n",
            "Enter Company Name: EY\n",
            "\n",
            "Enter 2-3 Bullet Points (Type 'done' or hit Enter on an empty line to finish):\n",
            "Bullet 1: ACCA\n",
            "Bullet 2: Data science\n",
            "Bullet 3: llms for acca\n",
            "Bullet 4: \n",
            "\n",
            "--- Generating Post... ---\n",
            "Hi all, I'm shounak and I work as an advisory specialist at EY. I recently completed my ACCA certification and it's safe to say that it was a challenging but rewarding experience.\n",
            "\n",
            "With the rise of technology, one of the areas that I'm particularly interested in is data science. I believe that data science has the potential to drive business growth and innovation, and I'm excited to explore this field further.\n",
            "\n",
            "During my studies, I came across some interesting applications of data science, particularly in the context of the ACCA certification. One area that caught my eye was the use of large language models (LLMs) to automate exam preparation and practice.\n",
            "\n",
            "Can we use LLMs to make studying for the ACCA certification easier? I believe that with the right approach, LLMs can be a huge help. For instance, they can provide personalized learning recommendations, auto-grade practice exams, and offer real-time feedback.\n",
            "\n",
            "I'd love to hear your thoughts on this. Have you used LLMs for studying or exam preparation? What do you think are some potential benefits and challenges of using LLMs in this context?\n",
            "\n",
            "Let's discuss!\n",
            "\n",
            "-----------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}